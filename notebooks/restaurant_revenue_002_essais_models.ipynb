{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGVK-UWLUnXx"
   },
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FyOiAB2qbjU"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reload modules before executing user code.\n",
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import dill\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import pendulum \n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from loguru import logger\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, VotingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (r2_score,\n",
    "                             mean_squared_error,\n",
    "                             mean_absolute_percentage_error,\n",
    "                             max_error,\n",
    "                             mean_absolute_error\n",
    "                            )\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, LabelEncoder\n",
    "from typing import Dict\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from settings.params import (DATA_DIR_INPUT,\n",
    "                             DATA_DIR_OUTPUT,\n",
    "                             MODEL_PARAMS,\n",
    "                             REPORT_DIR,\n",
    "                             TIMEZONE,\n",
    "                            HOME_DIR, \n",
    "                            )\n",
    "\n",
    "set_config(display=\"diagram\", print_changed_only=False)\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-22 23:56:06.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mExecution date: 2023-08-22T23:56:06.879319+00:00\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "EXECUTION_DATE = pendulum.now(tz=TIMEZONE)\n",
    "\n",
    "logger.info(f\"Execution date: {EXECUTION_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/baldita/Desktop/Courses/DIC3/mlops/project/mlops-project-dic3')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3adf50Ur29lc"
   },
   "source": [
    "### Entrainement des modeles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recuperation des donnees et verification de conformite\n",
    "\n",
    "A noter que les donnees que nous allons utiliser sont celles deja pretraitees dans le notebook d'exploration des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "      <th>P11</th>\n",
       "      <th>P13</th>\n",
       "      <th>P14</th>\n",
       "      <th>P15</th>\n",
       "      <th>P16</th>\n",
       "      <th>P19</th>\n",
       "      <th>P20</th>\n",
       "      <th>P21</th>\n",
       "      <th>P22</th>\n",
       "      <th>P23</th>\n",
       "      <th>P24</th>\n",
       "      <th>P26</th>\n",
       "      <th>P27</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Years Old</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.370000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.430657</td>\n",
       "      <td>1.430657</td>\n",
       "      <td>4.014599</td>\n",
       "      <td>4.408759</td>\n",
       "      <td>4.317518</td>\n",
       "      <td>4.372263</td>\n",
       "      <td>2.007299</td>\n",
       "      <td>3.357664</td>\n",
       "      <td>5.423358</td>\n",
       "      <td>5.153285</td>\n",
       "      <td>5.445255</td>\n",
       "      <td>5.489051</td>\n",
       "      <td>3.262774</td>\n",
       "      <td>5.080292</td>\n",
       "      <td>1.416058</td>\n",
       "      <td>1.386861</td>\n",
       "      <td>1.941606</td>\n",
       "      <td>4.905109</td>\n",
       "      <td>4.547445</td>\n",
       "      <td>2.270073</td>\n",
       "      <td>2.226277</td>\n",
       "      <td>3.423358</td>\n",
       "      <td>1.372263</td>\n",
       "      <td>1.470803</td>\n",
       "      <td>1.145985</td>\n",
       "      <td>3.135036</td>\n",
       "      <td>2.729927</td>\n",
       "      <td>1.941606</td>\n",
       "      <td>2.525547</td>\n",
       "      <td>1.138686</td>\n",
       "      <td>2.029197</td>\n",
       "      <td>2.211679</td>\n",
       "      <td>1.116788</td>\n",
       "      <td>2008.678832</td>\n",
       "      <td>7.058394</td>\n",
       "      <td>6.321168</td>\n",
       "      <td>4.453533e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496985</td>\n",
       "      <td>0.511567</td>\n",
       "      <td>2.910391</td>\n",
       "      <td>1.514900</td>\n",
       "      <td>1.032337</td>\n",
       "      <td>1.016462</td>\n",
       "      <td>1.209620</td>\n",
       "      <td>2.134235</td>\n",
       "      <td>2.296809</td>\n",
       "      <td>1.858567</td>\n",
       "      <td>1.834793</td>\n",
       "      <td>1.847561</td>\n",
       "      <td>1.910767</td>\n",
       "      <td>1.036527</td>\n",
       "      <td>2.729583</td>\n",
       "      <td>2.398677</td>\n",
       "      <td>3.505807</td>\n",
       "      <td>5.604467</td>\n",
       "      <td>3.708041</td>\n",
       "      <td>2.052630</td>\n",
       "      <td>1.230690</td>\n",
       "      <td>4.559609</td>\n",
       "      <td>2.304112</td>\n",
       "      <td>2.612024</td>\n",
       "      <td>2.067039</td>\n",
       "      <td>1.680887</td>\n",
       "      <td>5.536647</td>\n",
       "      <td>3.512093</td>\n",
       "      <td>5.230117</td>\n",
       "      <td>1.698540</td>\n",
       "      <td>3.436272</td>\n",
       "      <td>4.168211</td>\n",
       "      <td>1.790768</td>\n",
       "      <td>4.027359</td>\n",
       "      <td>3.590769</td>\n",
       "      <td>4.027359</td>\n",
       "      <td>2.576072e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.149870e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.999068e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.939804e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.166635e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.969694e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City Group        Type          P1          P2          P3          P4  \\\n",
       "count  137.000000  137.000000  137.000000  137.000000  137.000000  137.000000   \n",
       "mean     0.430657    1.430657    4.014599    4.408759    4.317518    4.372263   \n",
       "std      0.496985    0.511567    2.910391    1.514900    1.032337    1.016462   \n",
       "min      0.000000    0.000000    1.000000    1.000000    0.000000    3.000000   \n",
       "25%      0.000000    1.000000    2.000000    4.000000    4.000000    4.000000   \n",
       "50%      0.000000    1.000000    3.000000    5.000000    4.000000    4.000000   \n",
       "75%      1.000000    2.000000    4.000000    5.000000    5.000000    5.000000   \n",
       "max      1.000000    2.000000   12.000000    7.500000    7.500000    7.500000   \n",
       "\n",
       "               P5          P6          P7          P8          P9         P10  \\\n",
       "count  137.000000  137.000000  137.000000  137.000000  137.000000  137.000000   \n",
       "mean     2.007299    3.357664    5.423358    5.153285    5.445255    5.489051   \n",
       "std      1.209620    2.134235    2.296809    1.858567    1.834793    1.847561   \n",
       "min      1.000000    1.000000    1.000000    1.000000    4.000000    4.000000   \n",
       "25%      1.000000    2.000000    5.000000    4.000000    4.000000    5.000000   \n",
       "50%      2.000000    3.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "75%      2.000000    4.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "max      8.000000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "              P11         P13         P14         P15         P16         P19  \\\n",
       "count  137.000000  137.000000  137.000000  137.000000  137.000000  137.000000   \n",
       "mean     3.262774    5.080292    1.416058    1.386861    1.941606    4.905109   \n",
       "std      1.910767    1.036527    2.729583    2.398677    3.505807    5.604467   \n",
       "min      1.000000    3.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "25%      2.000000    5.000000    0.000000    0.000000    0.000000    2.000000   \n",
       "50%      3.000000    5.000000    0.000000    0.000000    0.000000    3.000000   \n",
       "75%      4.000000    5.000000    2.000000    2.000000    3.000000    5.000000   \n",
       "max     10.000000    7.500000   15.000000   10.000000   15.000000   25.000000   \n",
       "\n",
       "              P20         P21         P22         P23         P24         P26  \\\n",
       "count  137.000000  137.000000  137.000000  137.000000  137.000000  137.000000   \n",
       "mean     4.547445    2.270073    2.226277    3.423358    1.372263    1.470803   \n",
       "std      3.708041    2.052630    1.230690    4.559609    2.304112    2.612024   \n",
       "min      1.000000    1.000000    1.000000    1.000000    0.000000    0.000000   \n",
       "25%      2.000000    1.000000    1.000000    1.000000    0.000000    0.000000   \n",
       "50%      4.000000    1.000000    2.000000    2.000000    0.000000    0.000000   \n",
       "75%      5.000000    3.000000    3.000000    5.000000    2.000000    2.500000   \n",
       "max     15.000000   15.000000    5.000000   25.000000   10.000000   12.500000   \n",
       "\n",
       "              P27         P29         P30         P31         P32         P33  \\\n",
       "count  137.000000  137.000000  137.000000  137.000000  137.000000  137.000000   \n",
       "mean     1.145985    3.135036    2.729927    1.941606    2.525547    1.138686   \n",
       "std      2.067039    1.680887    5.536647    3.512093    5.230117    1.698540   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.500000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    3.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      2.000000    3.000000    4.000000    3.000000    3.000000    2.000000   \n",
       "max     12.500000    7.500000   25.000000   15.000000   25.000000    6.000000   \n",
       "\n",
       "              P35         P36         P37         Year       Month  \\\n",
       "count  137.000000  137.000000  137.000000   137.000000  137.000000   \n",
       "mean     2.029197    2.211679    1.116788  2008.678832    7.058394   \n",
       "std      3.436272    4.168211    1.790768     4.027359    3.590769   \n",
       "min      0.000000    0.000000    0.000000  1996.000000    1.000000   \n",
       "25%      0.000000    0.000000    0.000000  2007.000000    4.000000   \n",
       "50%      0.000000    0.000000    0.000000  2010.000000    8.000000   \n",
       "75%      4.000000    3.000000    2.000000  2011.000000   10.000000   \n",
       "max     15.000000   20.000000    8.000000  2014.000000   12.000000   \n",
       "\n",
       "        Years Old       revenue  \n",
       "count  137.000000  1.370000e+02  \n",
       "mean     6.321168  4.453533e+06  \n",
       "std      4.027359  2.576072e+06  \n",
       "min      1.000000  1.149870e+06  \n",
       "25%      4.000000  2.999068e+06  \n",
       "50%      5.000000  3.939804e+06  \n",
       "75%      8.000000  5.166635e+06  \n",
       "max     19.000000  1.969694e+07  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(str(DATA_DIR_OUTPUT) + '/train.csv')\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "      <th>P11</th>\n",
       "      <th>P13</th>\n",
       "      <th>P14</th>\n",
       "      <th>P15</th>\n",
       "      <th>P16</th>\n",
       "      <th>P19</th>\n",
       "      <th>P20</th>\n",
       "      <th>P21</th>\n",
       "      <th>P22</th>\n",
       "      <th>P23</th>\n",
       "      <th>P24</th>\n",
       "      <th>P26</th>\n",
       "      <th>P27</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Years Old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City Group  Type  P1   P2   P3   P4  P5  P6  P7  P8  P9  P10  P11  P13  \\\n",
       "0           1     1   1  4.0  4.0  4.0   1   2   5   4   5    5    5  4.0   \n",
       "1           1     2   3  4.0  4.0  4.0   2   2   5   3   4    4    2  5.0   \n",
       "2           0     1   3  4.0  4.0  4.0   2   2   5   4   4    5    4  5.0   \n",
       "3           1     2   2  4.0  4.0  4.0   2   3   5   4   5    4    3  5.0   \n",
       "4           1     1   2  4.0  4.0  4.0   1   2   5   4   5    4    3  4.0   \n",
       "\n",
       "   P14  P15  P16  P19  P20  P21  P22  P23  P24  P26  P27  P29  P30  P31  P32  \\\n",
       "0    0    0    0    5    5    3    1    4    0  0.0  0.0  3.0    0    0    0   \n",
       "1    0    0    0    5    5    3    2    1    0  0.0  0.0  3.0    0    0    0   \n",
       "2    0    0    0    5    5    5    5    5    0  0.0  0.0  3.0    0    0    0   \n",
       "3    0    0    0    4    4    3    2    2    0  0.0  0.0  3.0    0    4    0   \n",
       "4    0    0    0    1    5    3    1    1    0  0.0  0.0  3.0    0    0    0   \n",
       "\n",
       "   P33  P35  P36  P37  Year  Month  Years Old  \n",
       "0    0    0    0    0  2011      1          4  \n",
       "1    0    0    0    0  2011      3          4  \n",
       "2    0    0    0    0  2013     10          2  \n",
       "3    0    0    0    0  2013      5          2  \n",
       "4    0    0    0    0  2013      7          2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(str(DATA_DIR_OUTPUT) + '/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.370000e+02\n",
       "mean     4.453533e+06\n",
       "std      2.576072e+06\n",
       "min      1.149870e+06\n",
       "25%      2.999068e+06\n",
       "50%      3.939804e+06\n",
       "75%      5.166635e+06\n",
       "max      1.969694e+07\n",
       "Name: revenue, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['revenue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split des donnees \n",
    "Les donnees d'entrainement sont splittees en en donnees de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "( len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['revenue']    \n",
    "X_train = train_data.drop(['revenue'],axis=1)\n",
    "y_val = val_data['revenue']\n",
    "X_val = val_data.drop(['revenue'],axis=1)\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition des metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_actual,y_pred) -> Dict[str, float]:\n",
    "    # Root mean squared error\n",
    "    rmse = mean_squared_error(y_actual, y_pred, squared=False)\n",
    "    # mean absolute error\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    # R-squared: coefficient of determination\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    # max error: maximum value of absolute error (y_actual - y_pred)\n",
    "    maxerror = max_error(y_actual, y_pred)\n",
    "    return {\"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "            \"max_error\": maxerror\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "Pour les modeles nous allons entrainer sur les donnees de train dans un premier temps. Ensuite nous alons appliquer une ACP, afin de reduire la dimension des donnees (qui est de 36) avant d'entrainer sur les donnees de train. Enfin nous allons comparer l'ensemble des modeles obtenus avec ou sans ACP et en choisir le meilleur modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2ooHvxiQCol"
   },
   "source": [
    "Normalisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "p2fZSlUxziGT"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "X_val_scale = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Z5o97P2xKjF"
   },
   "source": [
    "Application dde l'ACP apres normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "c2-WeMW5vc9i"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#https://www.geeksforgeeks.org/principal-component-analysis-with-python/\n",
    "\n",
    "pca = PCA(n_components = 5)\n",
    "X_train_PCA = pca.fit_transform(X_train) \n",
    "X_test_PCA = pca.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGQwyflO3R1p"
   },
   "source": [
    "### Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fonctions de prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def predict_model(model,X,y_act):\\n    y_pred = model.predict(X)\\n    rms = mean_squared_error(y_act, y_pred,squared=False)\\n    return rms'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def predict_model(model,X,y_act):\n",
    "    y_pred = model.predict(X)\n",
    "    rms = mean_squared_error(y_act, y_pred,squared=False)\n",
    "    return rms\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def testDataPred(model,X):\\n  y_test = model.predict(X)\\n  dataFrame = pd.DataFrame({'Id': y_test['Id'], 'Prediction': y_test}) \\n  return dataFrame\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def testDataPred(model,X):\n",
    "  y_test = model.predict(X)\n",
    "  dataFrame = pd.DataFrame({'Id': y_test['Id'], 'Prediction': y_test}) \n",
    "  return dataFrame\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear avec le Lasso Regression\n",
    "Regresion lineaire avec la regularisation Lasso croisee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-22 23:28:00.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mTrain_LassoCV: {'rmse': 1813352.129708278, 'mae': 1368188.2988138413, 'r2': 0.35624066405779997, 'max_error': 7724057.245741125}\u001b[0m\n",
      "\u001b[32m2023-08-22 23:28:00.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mVal_LassoCV: {'rmse': 3742495.06785661, 'mae': 2501914.3127362416, 'r2': -0.14487007109329308, 'max_error': 13078463.48696628}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model_LR1 = linear_model.LassoCV(max_iter=10000,alphas=(0.0001,0.01,0.1,1),n_alphas=300,cv=5)\n",
    "model_LR1.fit(X_train_scale,y_train)\n",
    "y_train_LR_pred = model_LR1.predict(X_train_scale)\n",
    "y_val_LR_pred = model_LR1.predict(X_val_scale)\n",
    "train_metrics_lr1 = eval_metrics(y_train, y_train_LR_pred)\n",
    "val_metrics_lr1 = eval_metrics(y_val, y_val_LR_pred)\n",
    "\n",
    "\n",
    "logger.info(f\"Train_LassoCV: {train_metrics_lr1}\")\n",
    "logger.info(f\"Val_LassoCV: {val_metrics_lr1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear model avec l'analyse en composante princiapale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-22 23:28:04.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mTrain_LassoCV: {'rmse': 2166023.1916953875, 'mae': 1545647.4020882894, 'r2': 0.08148669505000306, 'max_error': 11346635.844886761}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_LR2 = linear_model.LassoCV(max_iter=100000,alphas=(0.0001,0.01,0.1,1),n_alphas=1000,cv=5)\n",
    "model_LR2.fit(X_train_PCA,y_train)\n",
    "y_train_LR2_pred = model_LR2.predict(X_train_PCA)\n",
    "train_metrics_lr2 = eval_metrics(y_train, y_train_LR2_pred)\n",
    "\n",
    "logger.info(f\"Train_LassoCV: {train_metrics_lr2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec les données normalisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-22 23:16:57.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mTrain_rf: {'rmse': 2088564.1955350847, 'mae': 1479142.8946937984, 'r2': 0.14600583352493202, 'max_error': 10633000.034060238}\u001b[0m\n",
      "\u001b[32m2023-08-22 23:16:57.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mVal_rf: {'rmse': 3438601.7120857923, 'mae': 1948756.625689457, 'r2': 0.033509745739770946, 'max_error': 15013282.852325318}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": randint(10,1000),\n",
    "    \"max_depth\": randint(1,10),\n",
    "    \"min_samples_split\": uniform(0.1,0.8),\n",
    "    'max_features':['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "RF_model = RandomForestRegressor()\n",
    "model_rf1 = RandomizedSearchCV(RF_model, params, cv=6, n_iter=100, scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "model_rf1.fit(X_train_scale, y_train)\n",
    "y_train_RF_pred = model_rf1.predict(X_train_scale)\n",
    "y_val_RF_pred = model_rf1.predict(X_val_scale)\n",
    "train_metrics_rf = eval_metrics(y_train, y_train_RF_pred)\n",
    "val_metrics_rf = eval_metrics(y_val, y_val_RF_pred)\n",
    "\n",
    "\n",
    "logger.info(f\"Train_rf: {train_metrics_rf}\")\n",
    "logger.info(f\"Val_rf: {val_metrics_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Avec les données transformés avec le PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-22 23:25:28.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mTrain_rf2: {'rmse': 2084789.24616046, 'mae': 1450898.6727801345, 'r2': 0.14909012593666315, 'max_error': 11447106.533460714}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_rf2 = RandomizedSearchCV(RF_model, params, cv=2, n_iter=100, scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "model_rf2.fit(X_train_PCA, y_train)\n",
    "y_train_rf2_pred = model_rf2.predict(X_train_PCA)\n",
    "train_metrics_rf_acp = eval_metrics(y_train, y_train_rf2_pred)\n",
    "\n",
    "logger.info(f\"Train_rf2: {train_metrics_rf_acp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST avec les données normalisés : data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-22 23:26:24.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mTrain_xgb: {'rmse': 341678.0694420003, 'mae': 184133.02981651376, 'r2': 0.9771443563571226, 'max_error': 1317315.0}\u001b[0m\n",
      "\u001b[32m2023-08-22 23:26:24.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mVal_xgb: {'rmse': 3293562.8853327916, 'mae': 2011588.919642857, 'r2': 0.11332257985096394, 'max_error': 14553092.0}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "import xgboost as xgb\n",
    "params = {\n",
    "    \"learning_rate\": uniform(0.001,1),\n",
    "    \"n_estimators\": randint(100,1000),\n",
    "    \"max_depth\": randint(1,10),     \n",
    "    \"colsample_bytree\": uniform(0.1,0.8),\n",
    "    \"reg_alpha\": [0.0001,0.001,0.01,0.1,1,10],\n",
    "    \"reg_lambda\": [0.0001,0.001,0.01,0.1,1,10]\n",
    "}\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "rand_xgb = RandomizedSearchCV(xgb_model, params, cv=2, n_iter=100, scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "rand_xgb.fit(X_train_scale, y_train)\n",
    "y_train_xgb_pred = rand_xgb.predict(X_train_scale)\n",
    "y_val_xgb_pred = rand_xgb.predict(X_val_scale)\n",
    "train_metrics_xgb = eval_metrics(y_train, y_train_xgb_pred)\n",
    "val_metrics_xgb = eval_metrics(y_val, y_val_xgb_pred)\n",
    "\n",
    "\n",
    "logger.info(f\"Train_xgb: {train_metrics_xgb}\")\n",
    "logger.info(f\"Val_xgb: {val_metrics_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etant donne que notre objectif est de faire des predictions assez precises, nous allons choisir le RMSE et MAE comme metriques principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------+------------------+--------------------+\n",
      "|    | Models                                      |       Train RMSE | VAL RMSE           |\n",
      "|----+---------------------------------------------+------------------+--------------------|\n",
      "|  0 | Lasso Regression - Standard scaling         |      1.81335e+06 | 3742495.06785661   |\n",
      "|  1 | Lasso Regression - PCA                      |      2.16602e+06 | --                 |\n",
      "|  2 | Random Forest - RandomSearchCV              |      2.08856e+06 | 3438601.7120857923 |\n",
      "|  3 | Random Forest - PCA-RandomSearchCV          |      2.08479e+06 | --                 |\n",
      "|  4 | XGBOOST - Standard scaling - RandomSearchCV | 341678           | 3293562.8853327916 |\n",
      "+----+---------------------------------------------+------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "dict = {\n",
    "        'Models'     : ['Lasso Regression - Standard scaling','Lasso Regression - PCA','Random Forest - RandomSearchCV','Random Forest - PCA-RandomSearchCV','XGBOOST - Standard scaling - RandomSearchCV'],\n",
    "        'Train RMSE' : [train_metrics_lr1[\"rmse\"],train_metrics_lr2[\"rmse\"],train_metrics_rf[\"rmse\"],train_metrics_rf_acp[\"rmse\"],train_metrics_xgb[\"rmse\"]],\n",
    "        'VAL RMSE'  : [val_metrics_lr1[\"rmse\"],\"--\",val_metrics_rf[\"rmse\"],\"--\",val_metrics_xgb[\"rmse\"]]\n",
    "}\n",
    "df = pd.DataFrame(dict)\n",
    "print(tabulate(df, headers = 'keys', tablefmt = 'psql')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------+------------------+--------------------+\n",
      "|    | Models                                      |        Train MAE | VAL MAE            |\n",
      "|----+---------------------------------------------+------------------+--------------------|\n",
      "|  0 | Lasso Regression - Standard scaling         |      1.36819e+06 | 2501914.3127362416 |\n",
      "|  1 | Lasso Regression - PCA                      |      1.54565e+06 | --                 |\n",
      "|  2 | Random Forest - RandomSearchCV              |      1.47914e+06 | 1948756.625689457  |\n",
      "|  3 | Random Forest - PCA-RandomSearchCV          |      1.4509e+06  | --                 |\n",
      "|  4 | XGBOOST - Standard scaling - RandomSearchCV | 184133           | 2011588.919642857  |\n",
      "+----+---------------------------------------------+------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "dict = {\n",
    "        'Models'     : ['Lasso Regression - Standard scaling','Lasso Regression - PCA','Random Forest - RandomSearchCV','Random Forest - PCA-RandomSearchCV','XGBOOST - Standard scaling - RandomSearchCV'],\n",
    "        'Train MAE' : [train_metrics_lr1[\"mae\"],train_metrics_lr2[\"mae\"],train_metrics_rf[\"mae\"],train_metrics_rf_acp[\"mae\"],train_metrics_xgb[\"mae\"]],\n",
    "        'VAL MAE'  : [val_metrics_lr1[\"mae\"],\"--\",val_metrics_rf[\"mae\"],\"--\",val_metrics_xgb[\"mae\"]]\n",
    "}\n",
    "df = pd.DataFrame(dict)\n",
    "print(tabulate(df, headers = 'keys', tablefmt = 'psql')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En se basant sur le score des **Root Mean Squared Error** et du **Mean Absolute Error**, nous pourrons dire que le meilleur modele est le XGBoost pour prédire nos données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engeristrement du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(str(HOME_DIR) + \"/models/bestmodel.pkl\",\"wb\")\n",
    "pickle.dump(rand_xgb,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking avec MlFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow.create_experiment(\"restaurant_revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 1608d9f036c94ef989da3c1bb3e19ebd\n",
      "version tag value: v1\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-23 00:32:23.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mTrain: {'rmse': 2186358.2026584535, 'mae': 1352751.0871559633, 'r2': 0.06415940669211007, 'max_error': 12288435.5}\u001b[0m\n",
      "\u001b[32m2023-08-23 00:32:23.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mVal: {'rmse': 3544197.505142372, 'mae': 1925417.3214285714, 'r2': -0.0267614627785957, 'max_error': 15762912.25}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Useful for multiple runs (only doing one run in this sample notebook)\n",
    "with mlflow.start_run(run_name=f\"{EXECUTION_DATE.strftime('%Y%m%d_%H%m%S')}-restaurant_revenue\",\n",
    "                      experiment_id=experiment_id,\n",
    "                      tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "                      description=\"restaurant revenue modeling\",) as mlf_run:\n",
    "    print(f\"run_id: {mlf_run.info.run_id}\")\n",
    "    print(f\"version tag value: {mlf_run.data.tags.get('version')}\")\n",
    "    print(\"--\")\n",
    "\n",
    "    # Select number of estimator\n",
    "    iterations = int(input(\"Iteration(s): \"))\n",
    "    mlflow.log_param(\"n_iters\", iterations)\n",
    "    # Model definition\n",
    "    params = {\n",
    "    \"learning_rate\": uniform(0.001,1),\n",
    "    \"n_estimators\": randint(100,1000),\n",
    "    \"max_depth\": randint(1,10),     \n",
    "    \"colsample_bytree\": uniform(0.1,0.8),\n",
    "    \"reg_alpha\": [0.0001,0.001,0.01,0.1,1,10],\n",
    "    \"reg_lambda\": [0.0001,0.001,0.01,0.1,1,10]\n",
    "    }\n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "    rand_xgb = RandomizedSearchCV(xgb_model, params, cv=2, n_iter=iterations, scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "    rand_xgb.fit(X_train_scale, y_train)\n",
    "\n",
    "    # Evaluate Metrics\n",
    "    y_train_xgb_pred = rand_xgb.predict(X_train_scale)\n",
    "    y_val_xgb_pred = rand_xgb.predict(X_val_scale)\n",
    "    train_metrics = eval_metrics(y_train, y_train_xgb_pred)\n",
    "    val_metrics = eval_metrics(y_val, y_val_xgb_pred)\n",
    "\n",
    "    # log out metrics\n",
    "    logger.info(f\"Train: {train_metrics}\")\n",
    "    logger.info(f\"Val: {val_metrics}\")\n",
    "    \n",
    "    # Infer model signature\n",
    "    predictions = rand_xgb.predict(X_train_scale)\n",
    "    signature = infer_signature(X_train_scale, predictions)\n",
    "\n",
    "    # Log parameter, metrics, and model to MLflow\n",
    "    for group_name, set_metrics in [(\"train\", train_metrics),\n",
    "                                    (\"test\", val_metrics),\n",
    "                                   ]:\n",
    "        for metric_name, metric_value in set_metrics.items():\n",
    "            mlflow.log_metric(f\"{group_name}_{metric_name}\", metric_value)\n",
    "    # mlflow.sklearn.log_model(reg, \"model\", signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-23 00:23:11 +0000] [95425] [INFO] Starting gunicorn 20.1.0\n",
      "[2023-08-23 00:23:11 +0000] [95425] [INFO] Listening at: http://0.0.0.0:5001 (95425)\n",
      "[2023-08-23 00:23:11 +0000] [95425] [INFO] Using worker: sync\n",
      "[2023-08-23 00:23:11 +0000] [95426] [INFO] Booting worker with pid: 95426\n",
      "[2023-08-23 00:23:11 +0000] [95427] [INFO] Booting worker with pid: 95427\n",
      "[2023-08-23 00:23:11 +0000] [95428] [INFO] Booting worker with pid: 95428\n",
      "[2023-08-23 00:23:11 +0000] [95429] [INFO] Booting worker with pid: 95429\n",
      "^C\n",
      "[2023-08-23 00:30:21 +0000] [95425] [INFO] Handling signal: int\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --host \"0.0.0.0\"  --port 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Restaurant_Revenue_Prediction_FinalPipeline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
